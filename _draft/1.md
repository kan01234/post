## Requrimetns

A Linux-powered edge device, operating in a remote setting, runs a program that generates periodic debug or error log messages. These logs are currently channeled through the system's default syslog mechanism.

The main features is allows an operator to remotely access log messages from the edge device though secure cloud server

To conserve network bandwidth and cloud storage, the device should only upload logs when explicitly requested by the operator, and only the specific logs that the operator needs.

### Assumption

#### Estimated Log Message Length

Let's make some estimations of the log message:

    Timestamp: 23 characters (yyyy-MM-dd HH:mm:ss.SSS)
    Log Level: 5 characters
    PID: Assuming a typical PID length of 5 digits
    Thread Name: 15 characters
    Logger Name: Let's assume an average of 20 characters
    Log Message: This is variable, but let's stick with our previous assumption of 100 bytes on average
    Exception Stack Trace: This is highly variable, but let's assume an average of 500 bytes when present (this can be adjusted based on your application's exception handling)
    Other characters and formatting: Let's add a buffer of 20 bytes for colons, spaces, and other formatting elements

#### Estimated Log Message / Day

Calculating the Average Log Message size:

    Log per day: 24 * 60 * 60 * 1000 (up to ms)
    Log message length with exception: 688 bytes
    Log message length without exception: 188 bytes
    Probability of exception: 10%

log message size = 86,400,000 * 10% * 688 bytes * 10% + 86,400,000 * 188 bytes = 20GB

## System Design

### Local Log Storage and Management on the Edge Device

#### File Structure

```
├── 2024-09-10/ 
    │   ├── 00/
    │   │   ├── 2024-09-10_00-00.json.gz 
    │   │   ├── 2024-09-10_00-00_1.json.gz
    │   │   ├── 2024-09-10_00-00_error.json.gz
    │   │   ├── 2024-09-10_00-01.json.gz
    │   │   ├── ...
    │   │   └── 2024-09-10_00-59.json.gz 
    │   ├── 01/
    │   │   ├── 2024-09-10_01-00.json
    │   │   ├── 2024-09-10_01-00_error.json
    │   │   ├── ... 
    │   └── ... 
    └── ... 
```

- Daily Directories: Logs are organized into directories named after the date (YYYY-MM-DD) they were generated.
- Hourly Subdirectories: Within each daily directory, there are subdirectories for each hour (00 to 23).
- Minutely Log Files: Inside the hourly directories, log files are created for each minute, following the naming convention: YYYY-MM-DD_HH-MM[_error].json.gz. The optional _error suffix denotes files containing error logs with exception stack traces.
- Sequence Numbers: If multiple log files are generated within the same minute (due to high volume or size limits), they are differentiated using sequence numbers (e.g., _1, _2, etc.).
- Compression: Log files are compressed using gzip (.gz extension), significantly reducing their storage footprint.

#### Estimated File Sizes

| Log Type   | Uncompressed Size (approx.) | Calculation                               | Compressed Size (gzip, approx.) |
|------------|-----------------------------|-------------------------------------------|---------------------------------|
| Non-Error  | 10.9 MB                     | 60,000 logs/min * 188 bytes/log / 1024^2 | 1.2 MB (50% compression)        |
| Error      | 4.13 MB                     | 60,000 logs/min * 10% * 500 bytes/log / 1024^2  | 0.25 MB (50% compression)        |

#### Log Rotation

Rotation Rules (Inferred):

- Time-Based Rotation: Log files are rotated every minute, creating a new file for each new minute.
- Size-Based Rotation (Optional): The presence of sequence numbers suggests that log files might also be rotated if they exceed a certain size limit, even within the same minute.
- Compression: Compression is likely applied immediately after rotation to save storage space.
- Error Log Separation: Error logs are separated into distinct files, potentially allowing for different retention policies or handling compared to non-error logs.

#### Log Retrieval and Filtering Process

**Scenario: Retrieving logs between 10:01:00 and 10:05:00**

1. **Receive Log Request** 
   * The device receives a request specifying the desired time range (e.g., 10:01:00 - 10:05:00) and any filtering criteria (e.g., log level). We will dicusss how to receive this request later.

2. **Identify Relevant Files**
   * Based on the requested time range, the device identifies:
     * The relevant daily directory (e.g., `2024-09-10`)
     * The corresponding hourly subdirectory (`10`)
     * The log files within that directory whose timestamps fall within the range (`2024-09-10_10-01.log.gz` to `2024-09-10_10-05.log.gz`)
   * If filtering by log level is required, it further selects only the files with the `_error` suffix (if filtering for errors) or all files (if no filtering).

3. **Process Each File Sequentially**

   * The device processes each selected log file one by one:
     * **Decompression:** The `.gz` file is decompressed into memory using `gunzip` or a similar tool.
     * **Filtering (if needed):**
       * The decompressed log data is parsed.
       * Log entries that do not match the requested log level are filtered out.
     * **Prepare for Upload:**
       * The filtered log entries (or the entire decompressed content if no filtering was applied) are prepared for upload.

4. **Upload to Cloud Server**

   * The device establishes a secure connection with the cloud server.
   * The prepared log data for each file is uploaded sequentially.
   * Memory used for decompression and filtering is freed after each upload to avoid excessive memory consumption.

**Memory Usage in Typical case:**

The largest files would likely be the non-error log files, which are estimated to be around 10.9 MB (uncompressed) or 1.2 MB (compressed).
In this case, the maximum memory usage would be around 10.9 MB.

#### Drawback: Potential Transfer of Unnecessary Log Data

Retrieving entire log files based on minute boundaries can lead to transferring unnecessary data. Even if a specific time range within a minute is requested, the whole file is retrieved and processed, wasting bandwidth and server resources.

#### Potential Improvements

**Finer-Grained Log Rotation**

Concept: Decrease log rotation interval (e.g., to 30 seconds or 15 seconds) for smaller files and less extraneous data transfer.

Benefits:

- More precise log retrieval
- Potential performance improvement on resource-constrained devices

Considerations:
- Increased number of files, potentially impacting file system performance
- Adjustments needed to logrotate and possibly the application's logging


**In-File Filtering with Structured Logs**

Concept: Filter directly within log files on the device by parsing and extracting entries matching the requested criteria.
    
Benefits:
- Minimizes unnecessary data transfer
- Works with minutely or finer-grained rotation

Considerations:
- Adds complexity to device-side logic
- Might require more CPU and memory for parsing and filtering
